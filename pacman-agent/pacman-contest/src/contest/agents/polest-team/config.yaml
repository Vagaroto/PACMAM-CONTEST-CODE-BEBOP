# PPO Agent Configuration
paths:
  # Directory to save and load model checkpoints
  checkpoint_dir: "checkpoints"
  # Directory to save episode trajectories for training
  trajectory_dir: "trajectories"

agent_settings:
  # Device for PyTorch (e.g., "cuda" or "cpu")
  device: "cpu" 
  # How often to reload the model checkpoint (in episodes)
  checkpoint_reload_interval: 10
  # If true, agent will only load model for inference, not save trajectories for training
  inference_mode: false
  # The reward bonus for visiting a new tile
  novelty_bonus: 0.5
  # The reward/penalty for moving closer/further from food
  food_proximity_bonus: 0.5

ppo_trainer_settings:
  gamma: 0.99
  lambda: 0.95
  clip_epsilon: 0.2
  value_loss_coef: 0.5
  entropy_bonus_coef: 0.01
  learning_rate: 0.00025
  minibatch_size: 64
  epochs_per_update: 10
